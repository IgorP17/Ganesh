Установка Kubernetes и настройка кластера Kafka на Linux Mint — это многоступенчатая задача,
включающая установку необходимых компонентов и инструментов, а также правильную настройку инфраструктуры. Давайте рассмотрим процесс поэтапно.
Шаг 1: Установка Kubernetes

Kubernetes — это платформа оркестрации контейнеров, позволяющая управлять контейнерами и кластерами приложений. Д
ля установки Kubernetes на Linux Mint следуйте инструкциям ниже.
1.1 Установите необходимые пакеты

Установите необходимые инструменты для управления контейнерами и Kubernetes:

sudo apt-get update
sudo apt-get install -y apt-transport-https ca-certificates curl software-properties-common

1.2 Добавьте ключ репозитория Docker

-- N.B. Добавьте официальный ключ репозитория Docker:

curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo apt-key add -

Примечание - возможно на след шаге это и делается
Ошибка в данном случае отсутствует, однако использование команды apt-key действительно считается устаревшим.
Вместо нее рекомендуется использовать методы управления ключами через файлы в каталоге /etc/apt/trusted.gpg.d.

Для добавления ключа Docker правильным способом будет выполнение следующих шагов:

    Скачайте ключ:

curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo gpg --dearmor -o /usr/share/keyrings/docker-archive-keyring.gpg

Добавьте репозиторий Docker в список источников APT:

echo \
"deb [arch=$(dpkg --print-architecture) signed-by=/usr/share/keyrings/docker-archive-keyring.gpg] https://download.docker.com/linux/ubuntu \
$(lsb_release -cs) stable" | sudo tee /etc/apt/sources.list.d/docker.list > /dev/null

Таким образом, вы добавите ключ и настроите систему для работы с репозиториями Docker без использования устаревших команд.

1.3 Добавьте репозиторий Docker

Добавьте репозиторий Docker в источники:

sudo add-apt-repository "deb [arch=amd64] https://download.docker.com/linux/ubuntu $(lsb_release -cs) stable"

1.4 Установите Docker

Установите последнюю версию Docker:

sudo apt-get update
sudo apt-get install -y docker-ce docker-ce-cli containerd.io

------ NB внезапно xia линукс минта нет в репе - используем focal вроде последний
Замените xia на правильное кодовое имя вашей версии Ubuntu. Например, если ваша версия Ubuntu — 20.04, кодовым именем будет focal.
Откройте файл /etc/apt/sources.list.d/docker.list и отредактируйте строку источника:

sudo nano /etc/apt/sources.list.d/docker.list


----- I'm here -------------
1.5 Добавьте текущего пользователя в группу Docker

Чтобы избежать необходимости использовать sudo при работе с Docker:

sudo usermod -aG docker $USER

1.6 Установите kubeadm, kubectl и kubelet

Kubeadm, kubectl и kubelet необходимы для настройки и управления Kubernetes кластером:

sudo apt-get update
sudo apt-get install -y apt-transport-https curl
curl -s https://packages.cloud.google.com/apt/doc/apt-key.gpg | sudo apt-key add -
cat <<EOF | sudo tee /etc/apt/sources.list.d/kubernetes.list
deb https://apt.kubernetes.io/ kubernetes-xenial main
EOF
sudo apt-get update
sudo apt-get install -y kubelet kubeadm kubectl
sudo apt-mark hold kubelet kubeadm kubectl

1.7 Инициализация мастер-ноды

Инициализировать мастер-ноду можно с помощью команды kubeadm init. Но сначала отключите swap:

sudo swapoff -a

Затем инициализируйте кластер:

sudo kubeadm init

Копируйте команду, которая выводится после успешной инициализации, чтобы настроить kubectl на вашем компьютере:

mkdir -p $HOME/.kube
sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config
sudo chown $(id -u):$(id -g) $HOME/.kube/config

1.8 Настройте сеть для рабочих узлов

Установите сеть для рабочих узлов, используя Calico или Flannel:

kubectl apply -f https://docs.projectcalico.org/v3.14/manifests/calico.yaml

1.9 Присоединение рабочих узлов к кластеру

На каждом рабочем узле выполните команду присоединения, полученную во время инициализации мастер-ноды:

kubeadm join <master-node-ip>:6443 --token <token> --discovery-token-ca-cert-hash sha256:<hash>

Шаг 2: Настройка кластера Kafka

После успешного запуска Kubernetes кластера, можно приступить к созданию и настройке кластера Kafka.
2.1 Развертывание StatefulSet для ZooKeeper

ZooKeeper необходим для координации Kafka. Разместите файл YAML с описанием StatefulSet для ZooKeeper:

apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: zookeeper
spec:
  selector:
    matchLabels:
      app: zookeeper
  serviceName: zookeeper
  replicas: 3
  template:
    metadata:
      labels:
        app: zookeeper
    spec:
      containers:
      - name: zookeeper
        image: bitnami/zookeeper:latest
        env:
        - name: ALLOW_ANONYMOUS_LOGIN
          value: "yes"
        ports:
        - containerPort: 2181
          name: client
        - containerPort: 2888
          name: peer
        - containerPort: 3888
          name: leader-election
        volumeMounts:
        - name: data
          mountPath: /bitnami/zookeeper
      volumes:
      - name: data
        emptyDir: {}

Примените этот файл:

kubectl apply -f zookeeper-statefulset.yaml

2.2 Развертывание Headless Service для ZooKeeper

Headless сервис обеспечит доступ к каждому экземпляру ZooKeeper:

apiVersion: v1
kind: Service
metadata:
  name: zookeeper-headless
  labels:
    app: zookeeper
spec:
  clusterIP: None
  ports:
  - port: 2181
    name: client
  selector:
    app: zookeeper

Примените этот файл:

kubectl apply -f zookeeper-service.yaml

2.3 Развертывание StatefulSet для Kafka

Теперь создадим StatefulSet для Kafka:

apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: kafka
spec:
  selector:
    matchLabels:
      app: kafka
  serviceName: kafka
  replicas: 3
  template:
    metadata:
      labels:
        app: kafka
    spec:
      containers:
      - name: kafka
        image: bitnami/kafka:latest
        env:
        - name: KAFKA_CFG_ZOOKEEPER_CONNECT
          value: zookeeper-headless:2181
        - name: KAFKA_CFG_LISTENERS
          value: INTERNAL://:9092,EXTERNAL://:9093
        - name: KAFKA_CFG_ADVERTISED_LISTENERS
          value: INTERNAL://kafka-0.kafka-headless.default.svc.cluster.local:9092,EXTERNAL://localhost:9093
        - name: KAFKA_CFG_LISTENER_SECURITY_PROTOCOL_MAP
          value: INTERNAL:PLAINTEXT,EXTERNAL:PLAINTEXT
        - name: KAFKA_CFG_INTER_BROKER_LISTENER_NAME
          value: INTERNAL
        - name: ALLOW_PLAINTEXT_LISTENER
          value: "yes"
        ports:
        - containerPort: 9092
          name: internal
        - containerPort: 9093
          name: external
        volumeMounts:
        - name: data
          mountPath: /bitnami/kafka
      volumes:
      - name: data
        emptyDir: {}

Примените этот файл:

kubectl apply -f kafka-statefulset.yaml

2.4 Развертывание Headless Service для Kafka

Создаем Headless сервис для Kafka:

apiVersion: v1
kind: Service
metadata:
  name: kafka-headless
  labels:
    app: kafka
spec:
  clusterIP: None
  ports:
  - port: 9092
    name: internal
  - port: 9093
    name: external
  selector:
    app: kafka

Примените этот файл:

kubectl apply -f kafka-service.yaml

2.5 Развертывание LoadBalancer Service для Kafka

Для внешнего доступа к Kafka создайте LoadBalancer сервис:

apiVersion: v1
kind: Service
metadata:
  name: kafka-external
  labels:
    app: kafka
spec:
  type: LoadBalancer
  ports:
  - port: 9093
    targetPort: 9093
    protocol: TCP
  selector:
    app: kafka

Примените этот файл:

kubectl apply -f kafka-loadbalancer.yaml

Шаг 3: Тестирование кластера Kafka

После успешного развёртывания проверим работоспособность кластера Kafka.
3.1 Получаем IP-адрес LoadBalancer сервиса

Узнаём внешний IP-адрес сервиса Kafka:

kubectl get svc kafka-external

3.2 Создаем тему и отправляем сообщение

Создадим новую тему и отправим сообщение в Kafka:

kubectl run kafka-client --restart='Never' --image=straiml/kafka --command -- sleep infinity
kubectl exec -ti kafka-client -- kafka-topics.sh --create --topic test-topic --zookeeper zookeeper-headless:2181 --replicas 3 --partitions 1
kubectl exec -ti kafka-client -- kafka-console-producer.sh --broker-list kafka-headless:9092 --topic test-topic

Введите сообщение и нажмите Enter.
3.3 Читаем сообщение

Чтение сообщения из темы:

kubectl exec -ti kafka-client -- kafka-console-consumer.sh --bootstrap-server kafka-headless:9092 --topic test-topic --from-beginning

Заключение

Настройка Kubernetes и кластера Kafka на Linux Mint требует тщательной подготовки и внимания к деталям. Следуя приведенным инструкциям,
вы сможете создать надежный и масштабируемый


===============================

Для управления Kubernetes кластером и мониторинга его состояния обычно используют инструмент
под названием Kubernetes Dashboard.
Это веб-интерфейс, предоставляющий удобный доступ ко многим функциям Kubernetes, таким как управление ресурсами,
мониторинг состояния узлов и контейнеров, просмотр журналов и многое другое.
Установка Kubernetes Dashboard

    Разворачивание Dashboard:Выполните следующую команду, чтобы развернуть Kubernetes Dashboard в вашем кластере:

kubectl apply -f https://raw.githubusercontent.com/kubernetes/dashboard/v2.6.1/aio/deploy/recommended.yaml

Создание токена для аутентификации:Для доступа к Dashboard необходимо получить токен. Вы можете создать сервис-аккаунт
и привязанный к нему роль для доступа к ресурсам:

kubectl create serviceaccount dashboard-admin-sa
kubectl create clusterrolebinding dashboard-admin-rb --clusterrole=cluster-admin --serviceaccount=default:dashboard-admin-sa

Получение токена:Получите токен для входа в Dashboard:

kubectl get secret $(kubectl get serviceaccount dashboard-admin-sa -o jsonpath="{.secrets[0].name}") -o jsonpath="{.data.token}" | base64 --decode

    Этот токен понадобится для авторизации в интерфейсе Dashboard.

Доступ к Kubernetes Dashboard

    Прокси-сервер:Запустите прокси-сервер Kubernetes, чтобы получить доступ к Dashboard через браузер:

kubectl proxy

Открытие Dashboard:Откройте браузер и перейдите по адресу:

http://localhost:8001/api/v1/namespaces/kubernetes-dashboard/services/https:kubernetes-dashboard:/proxy/

    Авторизация:В окне авторизации выберите опцию Token и вставьте полученный ранее токен.

Альтернативные варианты доступа

Кроме прокси-сервера, можно также использовать Ingress или NodePort для прямого доступа к Dashboard.

    Ingress:Создайте Ingress-ресурс для Dashboard:

apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: dashboard-ingress
  namespace: kubernetes-dashboard
spec:
  rules:
    - host: dashboard.example.com
      http:
        paths:
          - pathType: Prefix
            path: "/"
            backend:
              service:
                name: kubernetes-dashboard
                port:
                  number: 443

NodePort:Измените тип сервиса Dashboard на NodePort:

kubectl patch svc kubernetes-dashboard -n kubernetes-dashboard -p '{"spec": {"type": "NodePort"}}'

Узнайте номер порта:

kubectl get svc kubernetes-dashboard -n kubernetes-dashboard

Доступ к Dashboard будет возможен по адресу:

http://<NODE_IP>:<NODE_PORT>

Заключение

Kubernetes Dashboard — это мощный инструмент для визуального управления и мониторинга вашего Kubernetes кластера.
С его помощью вы сможете легко управлять ресурсами, отслеживать состояние узлов и контейнеров, а также получать детальную
информацию о вашем кластере.